{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rDv9a7n9zPJQ7OqebqCnEGAglkurUUSb",
      "authorship_tag": "ABX9TyPt3iHNHK+e0SnAd4LG11Y9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidparede/i2a2autonometa/blob/main/AutonoMeta_projeto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutonoMeta - Ferramenta de an√°lise autom√°tica de documentos fiscais\n",
        "\n",
        "Trabalho realizado para o curso de IA do I2A2 - grupo AutonoMeta, com o objetivo de permitir a an√°lise de dados fiscais de forma f√°cil e otimizada, atr√°ves do uso de linguagem natural. Todo projeto foi criado usando tecnologia open source e usando parametros de clean code. Os c√≥digos foram desenvolvidos em python, usou-se autogen como framework e o colab como IDE."
      ],
      "metadata": {
        "id": "GGJcsjTvhZn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Etapa 1: Instala√ß√£o de Depend√™ncias e Importa√ß√µes"
      ],
      "metadata": {
        "id": "o4Sfd_SShdoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autogen google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGshEx_Uhcs2",
        "outputId": "fbba601b-8e94-42c1-93d7-3bccc38998e9",
        "collapsed": true
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogen in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: ag2==0.9.3 in /usr/local/lib/python3.11/dist-packages (from autogen) (0.9.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (4.9.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (7.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (1.1.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (0.9.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.3->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.3->autogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.3->autogen) (0.4.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.3->autogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.3->autogen) (1.3.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.3->autogen) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.3->autogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.3->autogen) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.3->autogen) (2024.11.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 2: Importa√ß√µes e Configura√ß√£o Inicial"
      ],
      "metadata": {
        "id": "_vLEiLtxh9oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "from autogen import AssistantAgent, UserProxyAgent\n",
        "from IPython.display import display, Markdown\n",
        "import ipywidgets as widgets\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "import traceback\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Hg-BIq_xiEAW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONFIGURA√á√ÉO ---\n",
        "\n",
        "√â uma boa pr√°tica de desenvolvimento definir constantes no in√≠cio para f√°cil manuten√ß√£o, seguindo parametros de microsservi√ßo."
      ],
      "metadata": {
        "id": "jGiNP4GqiKbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar vari√°veis de ambiente\n",
        "ENDPOINT_API = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "MODEL_NAME = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "cozLQ9EEiRMS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SEGURAN√áA\n",
        "Para fins de seguran√ßa, a chave de API foi criptografada"
      ],
      "metadata": {
        "id": "gEgJcUO4ifJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "cuZtU3uINF3Q"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Etapa 3: Prepara√ß√£o dos Dados e importa√ß√£o de documentos fiscais"
      ],
      "metadata": {
        "id": "FnItNmnINTVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import pandas as pd\n",
        "import os\n",
        "\n",
        "# Defini√ß√£o do diret√≥rio onde os arquivos CSV est√£o localizados\n",
        "\n",
        "# Nomes dos arquivos CSV\n",
        "ARQUIVO_CABECALHO = '/content/202401_NFs_Cabecalho.csv'\n",
        "ARQUIVO_ITENS = '/content/202401_NFs_Itens.csv'\n",
        "\n",
        "def carregar_dados(diretorio, arquivo):\n",
        "    \"\"\"\n",
        "    Carrega um arquivo CSV em um DataFrame pandas.\n",
        "\n",
        "    Args:\n",
        "        diretorio (str): O diret√≥rio onde o arquivo est√° localizado.\n",
        "        arquivo (str): O nome do arquivo CSV.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: O DataFrame carregado.\n",
        "    \"\"\"\n",
        "    caminho_completo = os.path.join(diretorio, arquivo)\n",
        "    try:\n",
        "        df = pd.read_csv(caminho_completo)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo {arquivo} n√£o foi encontrado no diret√≥rio {diretorio}.\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "0dR-xW_XiVgk"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 4: Configura√ß√£o do Agente AutoGen"
      ],
      "metadata": {
        "id": "3-hRbqOOjcBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXTO_SISTEMA = f\"\"\"\n",
        "Voc√™ √© um analista de dados especialista em notas fiscais, preciso e direto.\n",
        "Sua tarefa √© responder √†s perguntas do usu√°rio usando os DataFrames do Pandas fornecidos.\n",
        "Os DataFrames dispon√≠veis s√£o `cabecalho_df` e `itens_df`.\n",
        "\n",
        "Schema do `cabecalho_df`: {list(cabecalho_df.columns) if cabecalho_df is not None else \"DataFrame not loaded\"}\n",
        "Schema do `itens_df`: {list(itens_df.columns) if itens_df is not None else \"DataFrame not loaded\"}\n",
        "\n",
        "Para responder, voc√™ deve:\n",
        "1.  Analisar a pergunta do usu√°rio.\n",
        "2.  Gerar e executar o c√≥digo Python necess√°rio para encontrar a resposta.\n",
        "3.  Apresentar a resposta final em linguagem natural, de forma clara e objetiva.\n",
        "4.  N√£o mostre o c√≥digo Python na sua resposta final, apenas o resultado.\n",
        "\"\"\"\n",
        "\n",
        "# Configura√ß√£o do LLM\n",
        "llm_config = {\n",
        "    \"config_list\": [{\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"base_url\": ENDPOINT_API,\n",
        "        \"api_key\": GOOGLE_API_KEY,\n",
        "    }],\n",
        "    \"cache_seed\": None # Desativa o cache para garantir novas respostas\n",
        "}\n",
        "\n",
        "# Set the environment variable for AutoGen's OpenAI client\n",
        "os.environ[\"OPENAI_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "dhyD8-zGuKbx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria√ß√£o do agente assistente com o contexto aprimorado\n",
        "assistant = AssistantAgent(\n",
        "    name=\"Analista_Fiscal\",\n",
        "    system_message=CONTEXTO_SISTEMA,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Cria√ß√£o do agente proxy do usu√°rio\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"Usuario_Proxy\",\n",
        "    human_input_mode=\"NEVER\", # O agente nunca pedir√° interven√ß√£o humana\n",
        "    max_consecutive_auto_reply=2, # Limita o n√∫mero de respostas autom√°ticas para evitar loops\n",
        "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\").rstrip(),\n",
        "    code_execution_config={\"work_dir\": \"analise\", \"use_docker\": False}\n",
        ")"
      ],
      "metadata": {
        "id": "aSKCaG_juqiz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "CONTEXTO_SISTEMA = f\"\"\"\n",
        "Voc√™ √© um analista de dados especialista em notas fiscais, preciso e direto.\n",
        "Sua tarefa √© responder √†s perguntas do usu√°rio usando os DataFrames do Pandas fornecidos.\n",
        "Os DataFrames dispon√≠veis s√£o `cabecalho_df` e `itens_df`.\n",
        "\n",
        "Schema do `cabecalho_df`: {list(cabecalho_df.columns) if cabecalho_df is not None else \"DataFrame not loaded\"}\n",
        "Schema do `itens_df`: {list(itens_df.columns) if itens_df is not None else \"DataFrame not loaded\"}\n",
        "\n",
        "Para responder, voc√™ deve:\n",
        "1.  Analisar a pergunta do usu√°rio.\n",
        "2.  Gerar e executar o c√≥digo Python necess√°rio para encontrar a resposta.\n",
        "3.  Apresentar a resposta final em linguagem natural, de forma clara e objetiva.\n",
        "4.  N√£o mostre o c√≥digo Python na sua resposta final, apenas o resultado.\n",
        "\"\"\"\n",
        "\n",
        "# Configura√ß√£o do LLM (sem altera√ß√µes, mas agora usa a chave de forma segura)\n",
        "llm_config = {\n",
        "    \"config_list\": [{\n",
        "        \"model\": 'gemini-2.0-flash',\n",
        "        \"base_url\": ENDPOINT_API,\n",
        "        \"api_key\": os.environ.get(\"GOOGLE_API_KEY\"), # Use OPENAI_API_KEY here\n",
        "    }],\n",
        "    \"cache_seed\": None # Desativa o cache para garantir novas respostas\n",
        "}\n",
        "\n",
        "# Set the environment variable for AutoGen's OpenAI client\n",
        "os.environ[\"OPENAI_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "\n",
        "# Cria√ß√£o do agente assistente com o contexto aprimorado\n",
        "assistant = AssistantAgent(\n",
        "    name=\"Analista_Fiscal\",\n",
        "    system_message=CONTEXTO_SISTEMA,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Cria√ß√£o do agente proxy do usu√°rio\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"Usuario_Proxy\",\n",
        "    human_input_mode=\"NEVER\", # O agente nunca pedir√° interven√ß√£o humana\n",
        "    max_consecutive_auto_reply=2, # Limita o n√∫mero de respostas autom√°ticas para evitar loops\n",
        "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\").rstrip(),\n",
        "    code_execution_config={\"work_dir\": \"analise\", \"use_docker\": False}\n",
        ")"
      ],
      "metadata": {
        "id": "dj1vyoq-jjae"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 5: Interface do Usu√°rio Interativa"
      ],
      "metadata": {
        "id": "AsnKob32j90C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Widgets para interface\n",
        "pergunta_input = widgets.Text(placeholder=\"Digite sua pergunta...\")\n",
        "botao_enviar = widgets.Button(description=\"Enviar\")\n",
        "saida = widgets.Output()\n",
        "\n",
        "def on_button_click(b):\n",
        "    with saida:\n",
        "        saida.clear_output()\n",
        "        pergunta = pergunta_input.value\n",
        "        print(f\"Processando: {pergunta}\")\n",
        "\n",
        "        # Iniciar chat com formata√ß√£o controlada\n",
        "        user_proxy.initiate_chat(\n",
        "            assistant,\n",
        "            message=f\"\"\"\n",
        "            Dados dispon√≠veis:\n",
        "            - Cabe√ßalho (cabecalho_df): {list('/content/202401_NFs_Cabecalho.csv'),\n",
        "            - Itens (itens_df): {list('/content/202401_NFs_Itens.csv'),\n",
        "            Pergunta do usu√°rio: {pergunta}\n",
        "\n",
        "            Instru√ß√µes:\n",
        "            1. Analise os dataframes relevantes\n",
        "            2. Execute e retorne apenas\n",
        "               - Resposta principal\n",
        "               - M√©todo utilizado\n",
        "               - Valores num√©ricos destacados\n",
        "            3. Focando apenas na resposta em linguagem natural\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Capturar e formatar √∫ltima resposta\n",
        "        ultima_resposta = assistant.last_message()['content']\n",
        "\n",
        "        # Filtragem de conte√∫do\n",
        "        partes_relevantes = [\n",
        "            linha for linha in ultima_resposta.split('\\n')\n",
        "            if not linha.startswith('```')\n",
        "        ]\n",
        "\n",
        "        # Exibir formatado\n",
        "        display(Markdown(f\"\"\"\n",
        "        **üìù Resposta:**\n",
        "        {''.join(partes_relevantes[1:-1]) if len(partes_relevantes) > 2 else ''.join(partes_relevantes)}\n",
        "\n",
        "        _‚ÑπÔ∏è Dados processados em {pd.Timestamp.now().strftime('%d/%m %H:%M')}_\n",
        "        \"\"\"))\n",
        "# Associa a fun√ß√£o ao evento de clique do bot√£o\n",
        "botao_enviar.on_click(on_button_click)\n",
        "\n",
        "# Exibe a interface final\n",
        "print(\"Sou AutonoMeta, como posso lhe ajudar hoje?.\")\n",
        "display(widgets.VBox([pergunta_input, botao_enviar, saida]))"
      ],
      "metadata": {
        "id": "n8VeEKJwz674"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}