{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rDv9a7n9zPJQ7OqebqCnEGAglkurUUSb",
      "authorship_tag": "ABX9TyPt3iHNHK+e0SnAd4LG11Y9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidparede/i2a2autonometa/blob/main/AutonoMeta_projeto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutonoMeta - Ferramenta de análise automática de documentos fiscais\n",
        "\n",
        "Trabalho realizado para o curso de IA do I2A2 - grupo AutonoMeta, com o objetivo de permitir a análise de dados fiscais de forma fácil e otimizada, atráves do uso de linguagem natural. Todo projeto foi criado usando tecnologia open source e usando parametros de clean code. Os códigos foram desenvolvidos em python, usou-se autogen como framework e o colab como IDE."
      ],
      "metadata": {
        "id": "GGJcsjTvhZn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Etapa 1: Instalação de Dependências e Importações"
      ],
      "metadata": {
        "id": "o4Sfd_SShdoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autogen google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGshEx_Uhcs2",
        "outputId": "fbba601b-8e94-42c1-93d7-3bccc38998e9",
        "collapsed": true
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogen in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: ag2==0.9.3 in /usr/local/lib/python3.11/dist-packages (from autogen) (0.9.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (4.9.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (7.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (1.1.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.3->autogen) (0.9.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.3->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.3->autogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.3->autogen) (0.4.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.3->autogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.3->autogen) (1.3.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.3->autogen) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.3->autogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.3->autogen) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.3->autogen) (2024.11.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 2: Importações e Configuração Inicial"
      ],
      "metadata": {
        "id": "_vLEiLtxh9oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "from autogen import AssistantAgent, UserProxyAgent\n",
        "from IPython.display import display, Markdown\n",
        "import ipywidgets as widgets\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "import traceback\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Hg-BIq_xiEAW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONFIGURAÇÃO ---\n",
        "\n",
        "É uma boa prática de desenvolvimento definir constantes no início para fácil manutenção, seguindo parametros de microsserviço."
      ],
      "metadata": {
        "id": "jGiNP4GqiKbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar variáveis de ambiente\n",
        "ENDPOINT_API = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "MODEL_NAME = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "cozLQ9EEiRMS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SEGURANÇA\n",
        "Para fins de segurança, a chave de API foi criptografada"
      ],
      "metadata": {
        "id": "gEgJcUO4ifJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "cuZtU3uINF3Q"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Etapa 3: Preparação dos Dados e importação de documentos fiscais"
      ],
      "metadata": {
        "id": "FnItNmnINTVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import pandas as pd\n",
        "import os\n",
        "\n",
        "# Definição do diretório onde os arquivos CSV estão localizados\n",
        "\n",
        "# Nomes dos arquivos CSV\n",
        "ARQUIVO_CABECALHO = '/content/202401_NFs_Cabecalho.csv'\n",
        "ARQUIVO_ITENS = '/content/202401_NFs_Itens.csv'\n",
        "\n",
        "def carregar_dados(diretorio, arquivo):\n",
        "    \"\"\"\n",
        "    Carrega um arquivo CSV em um DataFrame pandas.\n",
        "\n",
        "    Args:\n",
        "        diretorio (str): O diretório onde o arquivo está localizado.\n",
        "        arquivo (str): O nome do arquivo CSV.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: O DataFrame carregado.\n",
        "    \"\"\"\n",
        "    caminho_completo = os.path.join(diretorio, arquivo)\n",
        "    try:\n",
        "        df = pd.read_csv(caminho_completo)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo {arquivo} não foi encontrado no diretório {diretorio}.\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "0dR-xW_XiVgk"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 4: Configuração do Agente AutoGen"
      ],
      "metadata": {
        "id": "3-hRbqOOjcBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXTO_SISTEMA = f\"\"\"\n",
        "Você é um analista de dados especialista em notas fiscais, preciso e direto.\n",
        "Sua tarefa é responder às perguntas do usuário usando os DataFrames do Pandas fornecidos.\n",
        "Os DataFrames disponíveis são `cabecalho_df` e `itens_df`.\n",
        "\n",
        "Schema do `cabecalho_df`: {list(cabecalho_df.columns) if cabecalho_df is not None else \"DataFrame not loaded\"}\n",
        "Schema do `itens_df`: {list(itens_df.columns) if itens_df is not None else \"DataFrame not loaded\"}\n",
        "\n",
        "Para responder, você deve:\n",
        "1.  Analisar a pergunta do usuário.\n",
        "2.  Gerar e executar o código Python necessário para encontrar a resposta.\n",
        "3.  Apresentar a resposta final em linguagem natural, de forma clara e objetiva.\n",
        "4.  Não mostre o código Python na sua resposta final, apenas o resultado.\n",
        "\"\"\"\n",
        "\n",
        "# Configuração do LLM\n",
        "llm_config = {\n",
        "    \"config_list\": [{\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"base_url\": ENDPOINT_API,\n",
        "        \"api_key\": GOOGLE_API_KEY,\n",
        "    }],\n",
        "    \"cache_seed\": None # Desativa o cache para garantir novas respostas\n",
        "}\n",
        "\n",
        "# Set the environment variable for AutoGen's OpenAI client\n",
        "os.environ[\"OPENAI_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "dhyD8-zGuKbx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do agente assistente com o contexto aprimorado\n",
        "assistant = AssistantAgent(\n",
        "    name=\"Analista_Fiscal\",\n",
        "    system_message=CONTEXTO_SISTEMA,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Criação do agente proxy do usuário\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"Usuario_Proxy\",\n",
        "    human_input_mode=\"NEVER\", # O agente nunca pedirá intervenção humana\n",
        "    max_consecutive_auto_reply=2, # Limita o número de respostas automáticas para evitar loops\n",
        "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\").rstrip(),\n",
        "    code_execution_config={\"work_dir\": \"analise\", \"use_docker\": False}\n",
        ")"
      ],
      "metadata": {
        "id": "aSKCaG_juqiz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "CONTEXTO_SISTEMA = f\"\"\"\n",
        "Você é um analista de dados especialista em notas fiscais, preciso e direto.\n",
        "Sua tarefa é responder às perguntas do usuário usando os DataFrames do Pandas fornecidos.\n",
        "Os DataFrames disponíveis são `cabecalho_df` e `itens_df`.\n",
        "\n",
        "Schema do `cabecalho_df`: {list(cabecalho_df.columns) if cabecalho_df is not None else \"DataFrame not loaded\"}\n",
        "Schema do `itens_df`: {list(itens_df.columns) if itens_df is not None else \"DataFrame not loaded\"}\n",
        "\n",
        "Para responder, você deve:\n",
        "1.  Analisar a pergunta do usuário.\n",
        "2.  Gerar e executar o código Python necessário para encontrar a resposta.\n",
        "3.  Apresentar a resposta final em linguagem natural, de forma clara e objetiva.\n",
        "4.  Não mostre o código Python na sua resposta final, apenas o resultado.\n",
        "\"\"\"\n",
        "\n",
        "# Configuração do LLM (sem alterações, mas agora usa a chave de forma segura)\n",
        "llm_config = {\n",
        "    \"config_list\": [{\n",
        "        \"model\": 'gemini-2.0-flash',\n",
        "        \"base_url\": ENDPOINT_API,\n",
        "        \"api_key\": os.environ.get(\"GOOGLE_API_KEY\"), # Use OPENAI_API_KEY here\n",
        "    }],\n",
        "    \"cache_seed\": None # Desativa o cache para garantir novas respostas\n",
        "}\n",
        "\n",
        "# Set the environment variable for AutoGen's OpenAI client\n",
        "os.environ[\"OPENAI_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "\n",
        "# Criação do agente assistente com o contexto aprimorado\n",
        "assistant = AssistantAgent(\n",
        "    name=\"Analista_Fiscal\",\n",
        "    system_message=CONTEXTO_SISTEMA,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Criação do agente proxy do usuário\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"Usuario_Proxy\",\n",
        "    human_input_mode=\"NEVER\", # O agente nunca pedirá intervenção humana\n",
        "    max_consecutive_auto_reply=2, # Limita o número de respostas automáticas para evitar loops\n",
        "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\").rstrip(),\n",
        "    code_execution_config={\"work_dir\": \"analise\", \"use_docker\": False}\n",
        ")"
      ],
      "metadata": {
        "id": "dj1vyoq-jjae"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 5: Interface do Usuário Interativa"
      ],
      "metadata": {
        "id": "AsnKob32j90C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Widgets para interface\n",
        "pergunta_input = widgets.Text(placeholder=\"Digite sua pergunta...\")\n",
        "botao_enviar = widgets.Button(description=\"Enviar\")\n",
        "saida = widgets.Output()\n",
        "\n",
        "def on_button_click(b):\n",
        "    with saida:\n",
        "        saida.clear_output()\n",
        "        pergunta = pergunta_input.value\n",
        "        print(f\"Processando: {pergunta}\")\n",
        "\n",
        "        # Iniciar chat com formatação controlada\n",
        "        user_proxy.initiate_chat(\n",
        "            assistant,\n",
        "            message=f\"\"\"\n",
        "            Dados disponíveis:\n",
        "            - Cabeçalho (cabecalho_df): {list('/content/202401_NFs_Cabecalho.csv'),\n",
        "            - Itens (itens_df): {list('/content/202401_NFs_Itens.csv'),\n",
        "            Pergunta do usuário: {pergunta}\n",
        "\n",
        "            Instruções:\n",
        "            1. Analise os dataframes relevantes\n",
        "            2. Execute e retorne apenas\n",
        "               - Resposta principal\n",
        "               - Método utilizado\n",
        "               - Valores numéricos destacados\n",
        "            3. Focando apenas na resposta em linguagem natural\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Capturar e formatar última resposta\n",
        "        ultima_resposta = assistant.last_message()['content']\n",
        "\n",
        "        # Filtragem de conteúdo\n",
        "        partes_relevantes = [\n",
        "            linha for linha in ultima_resposta.split('\\n')\n",
        "            if not linha.startswith('```')\n",
        "        ]\n",
        "\n",
        "        # Exibir formatado\n",
        "        display(Markdown(f\"\"\"\n",
        "        **📝 Resposta:**\n",
        "        {''.join(partes_relevantes[1:-1]) if len(partes_relevantes) > 2 else ''.join(partes_relevantes)}\n",
        "\n",
        "        _ℹ️ Dados processados em {pd.Timestamp.now().strftime('%d/%m %H:%M')}_\n",
        "        \"\"\"))\n",
        "# Associa a função ao evento de clique do botão\n",
        "botao_enviar.on_click(on_button_click)\n",
        "\n",
        "# Exibe a interface final\n",
        "print(\"Sou AutonoMeta, como posso lhe ajudar hoje?.\")\n",
        "display(widgets.VBox([pergunta_input, botao_enviar, saida]))"
      ],
      "metadata": {
        "id": "n8VeEKJwz674"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}